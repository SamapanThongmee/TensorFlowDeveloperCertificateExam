{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
    "# Please note that the weight of the grade for the question is relative\n",
    "# to its difficulty. So your Category 1 question will score significantly\n",
    "# less than your Category 5 question.\n",
    "#\n",
    "# Don't use lambda layers in your model.\n",
    "# You do not need them to solve the question.\n",
    "# Lambda layers are not supported by the grading infrastructure.\n",
    "#\n",
    "# You must use the Submit and Test button to submit your model\n",
    "# at least once in this category before you finally submit your exam,\n",
    "# otherwise you will score zero for this category.\n",
    "# ==============================================================================\n",
    "#\n",
    "# BASIC DATASETS QUESTION\n",
    "#\n",
    "# Create a classifier for the German Traffic Signs dataset that classifies\n",
    "# images of traffic signs into 43 classes.\n",
    "# ==============================================================================\n",
    "#\n",
    "# ABOUT THE DATASET\n",
    "#\n",
    "# The dataset contains traffic sign boards from the streets captured into\n",
    "# image files. There are 43 unique classes in total. The images are of shape\n",
    "# (30,30,3).\n",
    "# ==============================================================================\n",
    "#\n",
    "# INSTRUCTIONS\n",
    "#\n",
    "# We have already divided the data for training and validation.\n",
    "#\n",
    "# Complete the code in following functions:\n",
    "# 1. preprocess()\n",
    "# 2. solution_model()\n",
    "#\n",
    "# Your code will fail to be graded if the following criteria are not met:\n",
    "# 1. The input shape of your model must be (30,30,3), because the testing\n",
    "#    infrastructure expects inputs according to this specification.\n",
    "# 2. The last layer of your model must be a Dense layer with 43 neurons\n",
    "#    activated by softmax since this dataset has 43 classes.\n",
    "#\n",
    "# HINT: Your neural network must have a validation accuracy of approximately\n",
    "# 0.95 or above on the normalized validation dataset for top marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\samapant\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\samapant\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\samapant\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement urllib (from versions: none)\n",
      "ERROR: No matching distribution found for urllib\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\n",
      "ERROR: No matching distribution found for zipfile\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install urllib\n",
    "%pip install zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "# This function downloads and extracts the dataset to the directory that\n",
    "# contains this file.\n",
    "# DO NOT CHANGE THIS CODE\n",
    "# (unless you need to change https to http)\n",
    "def download_and_extract_data():\n",
    "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip'\n",
    "    urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
    "    with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "# COMPLETE THE CODE IN THIS FUNCTION\n",
    "def preprocess(image, label):\n",
    "    # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255)\n",
    "    image = image / 255.0\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# This function loads the data, normalizes and resizes the images, splits it into\n",
    "# train and validation sets, defines the model, compiles it and finally\n",
    "# trains the model. The trained model is returned from this function.\n",
    "\n",
    "# COMPLETE THE CODE IN THIS FUNCTION.\n",
    "def solution_model():\n",
    "    # Downloads and extracts the dataset to the directory that\n",
    "    # contains this file.\n",
    "    download_and_extract_data()\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    IMG_SIZE = 30\n",
    "\n",
    "    # The following code reads the training and validation data from their\n",
    "    # respective directories, resizes them into the specified image size\n",
    "    # and splits them into batches. You must fill in the image_size\n",
    "    # argument for both training and validation data.\n",
    "    # HINT: Image size is a tuple\n",
    "\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory='train/',\n",
    "        label_mode='categorical',\n",
    "        image_size=(30,30),  # YOUR CODE HERE\n",
    "        batch_size = BATCH_SIZE)\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory='validation/',\n",
    "        label_mode='categorical',\n",
    "        image_size=(30,30),  # YOUR CODE HERE\n",
    "        batch_size = BATCH_SIZE)\n",
    "\n",
    "    # Normalizes train and validation datasets using the\n",
    "    # preprocess() function.\n",
    "    # Also makes other calls, as evident from the code, to prepare them for\n",
    "    # training.\n",
    "    # Do not batch or resize the images in the dataset here since it's already\n",
    "    # been done previously.\n",
    "\n",
    "    train_ds = train_ds.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
    "        tf.data.experimental.AUTOTUNE)\n",
    "    val_ds = val_ds.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Code to define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # ADD LAYERS OF THE MODEL HERE\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='swish', input_shape=(30, 30, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(2, 2), strides=(1, 1), padding='valid', activation='swish'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(512, activation='swish'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(256, activation='swish'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(128, activation='swish'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(64, activation='swish'),\n",
    "\n",
    "        # If you don't adhere to the instructions in the following comments,\n",
    "        # tests will fail to grade your model:\n",
    "        # The input layer of your model must have an input shape of\n",
    "        # (30,30,3).\n",
    "        # Make sure your last layer has 43 neurons activated by softmax.\n",
    "        tf.keras.layers.Dense(43, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # Code to compile and train the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Accuracy >= 0.95\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.95:\n",
    "                print(\"\\nReached 95.0% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # Checkpoint\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"Question_3.h5\",\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True\n",
    "        )\n",
    "\n",
    "\n",
    "    model.fit(\n",
    "        # YOUR CODE HERE\n",
    "        # train_ds,\n",
    "        train_ds.repeat(),\n",
    "        steps_per_epoch=4,\n",
    "        epochs=1000,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=4,\n",
    "        verbose=1,\n",
    "        callbacks=[callbacks, checkpoint])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31367 files belonging to 43 classes.\n",
      "Found 7842 files belonging to 43 classes.\n",
      "Epoch 1/1000\n",
      "4/4 [==============================] - 5s 561ms/step - loss: 8.0771 - accuracy: 0.0000e+00 - val_loss: 3.7092 - val_accuracy: 0.0312\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 6.5263 - accuracy: 0.0469 - val_loss: 3.7035 - val_accuracy: 0.0078\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 5.3355 - accuracy: 0.0234 - val_loss: 3.7448 - val_accuracy: 0.0312\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 4.3609 - accuracy: 0.0547 - val_loss: 3.7366 - val_accuracy: 0.0703\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 4.7068 - accuracy: 0.0469 - val_loss: 3.7386 - val_accuracy: 0.1016\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 3.9226 - accuracy: 0.0859 - val_loss: 3.7472 - val_accuracy: 0.0781\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 3.9863 - accuracy: 0.0469 - val_loss: 3.7557 - val_accuracy: 0.0625\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 3.6975 - accuracy: 0.0859 - val_loss: 3.7459 - val_accuracy: 0.0547\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 3.4764 - accuracy: 0.1250 - val_loss: 3.7399 - val_accuracy: 0.0625\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 3.6756 - accuracy: 0.1094 - val_loss: 3.7311 - val_accuracy: 0.0625\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 3.4384 - accuracy: 0.1719 - val_loss: 3.7167 - val_accuracy: 0.1016\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 3.6545 - accuracy: 0.1406 - val_loss: 3.7226 - val_accuracy: 0.1484\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 3.4139 - accuracy: 0.1328 - val_loss: 3.7091 - val_accuracy: 0.1406\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 1s 235ms/step - loss: 3.3176 - accuracy: 0.1953 - val_loss: 3.6980 - val_accuracy: 0.1641\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 3.3454 - accuracy: 0.1406 - val_loss: 3.6993 - val_accuracy: 0.1641\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 3.3244 - accuracy: 0.1797 - val_loss: 3.6877 - val_accuracy: 0.1797\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 2.9598 - accuracy: 0.1641 - val_loss: 3.6886 - val_accuracy: 0.1797\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 3.0529 - accuracy: 0.1797 - val_loss: 3.6733 - val_accuracy: 0.1797\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 3.2252 - accuracy: 0.2109 - val_loss: 3.6679 - val_accuracy: 0.1484\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 3.0452 - accuracy: 0.2109 - val_loss: 3.6532 - val_accuracy: 0.1406\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 2.9026 - accuracy: 0.2500 - val_loss: 3.6367 - val_accuracy: 0.1172\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 2.9689 - accuracy: 0.2812 - val_loss: 3.6376 - val_accuracy: 0.1094\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 3.0540 - accuracy: 0.3125 - val_loss: 3.6307 - val_accuracy: 0.0625\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 2.6281 - accuracy: 0.3594 - val_loss: 3.6033 - val_accuracy: 0.1484\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 2.7133 - accuracy: 0.3359 - val_loss: 3.5968 - val_accuracy: 0.1016\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 2.5363 - accuracy: 0.3516 - val_loss: 3.5627 - val_accuracy: 0.1172\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 2.6867 - accuracy: 0.3203 - val_loss: 3.5633 - val_accuracy: 0.1172\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 2.5226 - accuracy: 0.3672 - val_loss: 3.5509 - val_accuracy: 0.1562\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 2.6544 - accuracy: 0.3203 - val_loss: 3.5339 - val_accuracy: 0.1641\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 2.4946 - accuracy: 0.3047 - val_loss: 3.5114 - val_accuracy: 0.1562\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 2.6293 - accuracy: 0.3203 - val_loss: 3.4891 - val_accuracy: 0.2344\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 2.5549 - accuracy: 0.4062 - val_loss: 3.5170 - val_accuracy: 0.1719\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 2.2793 - accuracy: 0.3906 - val_loss: 3.5117 - val_accuracy: 0.2031\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 2.3311 - accuracy: 0.4062 - val_loss: 3.4900 - val_accuracy: 0.2266\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 2.2906 - accuracy: 0.4453 - val_loss: 3.4393 - val_accuracy: 0.2266\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 2.3369 - accuracy: 0.4141 - val_loss: 3.4168 - val_accuracy: 0.2031\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 2.1736 - accuracy: 0.3984 - val_loss: 3.3446 - val_accuracy: 0.2188\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 2.1500 - accuracy: 0.4297 - val_loss: 3.3687 - val_accuracy: 0.1641\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 2.2634 - accuracy: 0.4062 - val_loss: 3.3967 - val_accuracy: 0.1719\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 1.8203 - accuracy: 0.5156 - val_loss: 3.3287 - val_accuracy: 0.3203\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 2.0324 - accuracy: 0.4531 - val_loss: 3.2609 - val_accuracy: 0.2891\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 2.0485 - accuracy: 0.3828 - val_loss: 3.3592 - val_accuracy: 0.2578\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 2.3655 - accuracy: 0.3594 - val_loss: 3.2767 - val_accuracy: 0.2344\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 2.0181 - accuracy: 0.4844 - val_loss: 3.2504 - val_accuracy: 0.2578\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.5954 - accuracy: 0.6094 - val_loss: 3.2310 - val_accuracy: 0.2891\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 1.9099 - accuracy: 0.4844 - val_loss: 3.1250 - val_accuracy: 0.3125\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 1.9687 - accuracy: 0.4375 - val_loss: 3.1643 - val_accuracy: 0.2500\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.9271 - accuracy: 0.4375 - val_loss: 3.1342 - val_accuracy: 0.2422\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 2.0024 - accuracy: 0.5312 - val_loss: 3.1315 - val_accuracy: 0.2578\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 1.9800 - accuracy: 0.4531 - val_loss: 3.1329 - val_accuracy: 0.2891\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 1.9572 - accuracy: 0.4609 - val_loss: 3.0995 - val_accuracy: 0.3594\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 1.7297 - accuracy: 0.5078 - val_loss: 3.0949 - val_accuracy: 0.3750\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 1.7488 - accuracy: 0.5078 - val_loss: 2.9788 - val_accuracy: 0.4297\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.6833 - accuracy: 0.5703 - val_loss: 3.1492 - val_accuracy: 0.3203\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.8094 - accuracy: 0.4844 - val_loss: 3.0155 - val_accuracy: 0.3203\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 1.7473 - accuracy: 0.4688 - val_loss: 3.0549 - val_accuracy: 0.3438\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.4112 - accuracy: 0.5469 - val_loss: 2.7580 - val_accuracy: 0.4375\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 1.7685 - accuracy: 0.4688 - val_loss: 2.7930 - val_accuracy: 0.3750\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 1.4899 - accuracy: 0.5312 - val_loss: 2.7361 - val_accuracy: 0.3594\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.6061 - accuracy: 0.5391 - val_loss: 2.7015 - val_accuracy: 0.4453\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 1.4141 - accuracy: 0.6094 - val_loss: 2.6595 - val_accuracy: 0.4609\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.6908 - accuracy: 0.5078 - val_loss: 2.7441 - val_accuracy: 0.4609\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 1.2252 - accuracy: 0.6484 - val_loss: 2.7123 - val_accuracy: 0.4922\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 1.4117 - accuracy: 0.6328 - val_loss: 2.7051 - val_accuracy: 0.4219\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 1.5027 - accuracy: 0.5938 - val_loss: 2.5457 - val_accuracy: 0.5000\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 1.5093 - accuracy: 0.5078 - val_loss: 2.6178 - val_accuracy: 0.4141\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 1.5907 - accuracy: 0.5469 - val_loss: 2.6722 - val_accuracy: 0.4688\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 1.6714 - accuracy: 0.6250 - val_loss: 2.5301 - val_accuracy: 0.5312\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 1.4750 - accuracy: 0.5078 - val_loss: 2.5724 - val_accuracy: 0.4375\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 1.3328 - accuracy: 0.5859 - val_loss: 2.5410 - val_accuracy: 0.4062\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 1.5853 - accuracy: 0.5938 - val_loss: 2.4797 - val_accuracy: 0.4766\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 1.5119 - accuracy: 0.5625 - val_loss: 2.3916 - val_accuracy: 0.5234\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.3604 - accuracy: 0.6094 - val_loss: 2.3551 - val_accuracy: 0.5000\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 1.4762 - accuracy: 0.5938 - val_loss: 2.4506 - val_accuracy: 0.5078\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 1.0934 - accuracy: 0.6797 - val_loss: 2.3801 - val_accuracy: 0.5312\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 1.1644 - accuracy: 0.6562 - val_loss: 2.3236 - val_accuracy: 0.5234\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 1.2360 - accuracy: 0.6719 - val_loss: 2.2813 - val_accuracy: 0.5781\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.2196 - accuracy: 0.6016 - val_loss: 2.1842 - val_accuracy: 0.5547\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.2460 - accuracy: 0.6328 - val_loss: 2.1805 - val_accuracy: 0.5938\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 1.1799 - accuracy: 0.6719 - val_loss: 1.9388 - val_accuracy: 0.6328\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 1.1856 - accuracy: 0.6250 - val_loss: 1.9900 - val_accuracy: 0.6406\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 1.2296 - accuracy: 0.6250 - val_loss: 2.0936 - val_accuracy: 0.5938\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 1.2482 - accuracy: 0.6562 - val_loss: 2.0504 - val_accuracy: 0.6016\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 1.0745 - accuracy: 0.7188 - val_loss: 2.0449 - val_accuracy: 0.5703\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 1.1574 - accuracy: 0.6406 - val_loss: 2.0093 - val_accuracy: 0.6016\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 1.2330 - accuracy: 0.6250 - val_loss: 1.9242 - val_accuracy: 0.5625\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 1.0415 - accuracy: 0.6484 - val_loss: 1.9728 - val_accuracy: 0.5391\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 1.2011 - accuracy: 0.6016 - val_loss: 1.8071 - val_accuracy: 0.5703\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 1.2496 - accuracy: 0.6406 - val_loss: 1.8476 - val_accuracy: 0.6172\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 1.0494 - accuracy: 0.7031 - val_loss: 1.9137 - val_accuracy: 0.6328\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 1.0215 - accuracy: 0.7031 - val_loss: 1.9514 - val_accuracy: 0.5703\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 1s 220ms/step - loss: 1.0153 - accuracy: 0.6719 - val_loss: 1.9216 - val_accuracy: 0.6172\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 1.1144 - accuracy: 0.6562 - val_loss: 1.8367 - val_accuracy: 0.6797\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.9932 - accuracy: 0.6875 - val_loss: 1.8255 - val_accuracy: 0.6719\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 1.1018 - accuracy: 0.7188 - val_loss: 1.7961 - val_accuracy: 0.6719\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 0.9903 - accuracy: 0.7266 - val_loss: 1.5308 - val_accuracy: 0.6797\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.9806 - accuracy: 0.7188 - val_loss: 1.5656 - val_accuracy: 0.6562\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.9502 - accuracy: 0.6797 - val_loss: 1.6439 - val_accuracy: 0.6797\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 1.0205 - accuracy: 0.6719 - val_loss: 1.5166 - val_accuracy: 0.7031\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.9728 - accuracy: 0.6719 - val_loss: 1.4625 - val_accuracy: 0.6875\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.9178 - accuracy: 0.7031 - val_loss: 1.5478 - val_accuracy: 0.6875\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.9769 - accuracy: 0.7031 - val_loss: 1.4330 - val_accuracy: 0.6953\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.8971 - accuracy: 0.7109 - val_loss: 1.5038 - val_accuracy: 0.6641\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 1.0124 - accuracy: 0.7188 - val_loss: 1.5321 - val_accuracy: 0.6641\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 1.0106 - accuracy: 0.7031 - val_loss: 1.4363 - val_accuracy: 0.7188\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.9383 - accuracy: 0.7344 - val_loss: 1.6958 - val_accuracy: 0.6016\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.9987 - accuracy: 0.7188 - val_loss: 1.5946 - val_accuracy: 0.6250\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 1.0230 - accuracy: 0.7422 - val_loss: 1.6463 - val_accuracy: 0.6953\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 1.2623 - accuracy: 0.6250 - val_loss: 1.5205 - val_accuracy: 0.7109\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 1.1061 - accuracy: 0.6484 - val_loss: 1.4306 - val_accuracy: 0.6953\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.9181 - accuracy: 0.7109 - val_loss: 1.2710 - val_accuracy: 0.7969\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.8755 - accuracy: 0.7422 - val_loss: 1.2793 - val_accuracy: 0.7891\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.7763 - accuracy: 0.7969 - val_loss: 1.2067 - val_accuracy: 0.8438\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 1s 195ms/step - loss: 0.7420 - accuracy: 0.7891 - val_loss: 1.2716 - val_accuracy: 0.7891\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.9483 - accuracy: 0.6797 - val_loss: 1.0962 - val_accuracy: 0.8516\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 0.8549 - accuracy: 0.6953 - val_loss: 1.1503 - val_accuracy: 0.7812\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.8934 - accuracy: 0.6953 - val_loss: 1.1260 - val_accuracy: 0.7031\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 1.0961 - accuracy: 0.6875 - val_loss: 1.1336 - val_accuracy: 0.7109\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 1.0357 - accuracy: 0.7266 - val_loss: 1.0836 - val_accuracy: 0.7344\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.9517 - accuracy: 0.6875 - val_loss: 1.0948 - val_accuracy: 0.6953\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.8594 - accuracy: 0.7344 - val_loss: 1.3127 - val_accuracy: 0.5938\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 1s 205ms/step - loss: 1.0894 - accuracy: 0.6484 - val_loss: 0.8813 - val_accuracy: 0.8047\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.8543 - accuracy: 0.7188 - val_loss: 0.9701 - val_accuracy: 0.7344\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 1s 199ms/step - loss: 0.8480 - accuracy: 0.7188 - val_loss: 0.9426 - val_accuracy: 0.7578\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.9270 - accuracy: 0.7812 - val_loss: 1.0085 - val_accuracy: 0.8203\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.9405 - accuracy: 0.7266 - val_loss: 1.0787 - val_accuracy: 0.8281\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.6470 - accuracy: 0.8047 - val_loss: 1.0720 - val_accuracy: 0.8125\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.6943 - accuracy: 0.7969 - val_loss: 0.9409 - val_accuracy: 0.7812\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.8421 - accuracy: 0.7578 - val_loss: 0.9516 - val_accuracy: 0.7188\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.8443 - accuracy: 0.7422 - val_loss: 1.0044 - val_accuracy: 0.7422\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.8444 - accuracy: 0.7578 - val_loss: 0.8893 - val_accuracy: 0.8672\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.8358 - accuracy: 0.7500 - val_loss: 0.9738 - val_accuracy: 0.8516\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.4318 - accuracy: 0.8828 - val_loss: 1.0789 - val_accuracy: 0.8047\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6267 - accuracy: 0.8203 - val_loss: 0.8054 - val_accuracy: 0.8438\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6290 - accuracy: 0.7812 - val_loss: 0.8272 - val_accuracy: 0.7969\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.6288 - accuracy: 0.8438 - val_loss: 0.6917 - val_accuracy: 0.8359\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.5516 - accuracy: 0.8203 - val_loss: 0.6158 - val_accuracy: 0.8672\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.6769 - accuracy: 0.7812 - val_loss: 0.5754 - val_accuracy: 0.9062\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6684 - accuracy: 0.8125 - val_loss: 0.5410 - val_accuracy: 0.8516\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.6167 - accuracy: 0.8281 - val_loss: 0.7437 - val_accuracy: 0.7734\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.6624 - accuracy: 0.7891 - val_loss: 0.6741 - val_accuracy: 0.8828\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.9136 - accuracy: 0.7656 - val_loss: 0.7914 - val_accuracy: 0.8203\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.8188 - accuracy: 0.7656 - val_loss: 0.7559 - val_accuracy: 0.8047\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.7977 - accuracy: 0.7500 - val_loss: 0.9700 - val_accuracy: 0.7656\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 1s 326ms/step - loss: 0.6079 - accuracy: 0.7891 - val_loss: 0.9215 - val_accuracy: 0.8281\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 1s 368ms/step - loss: 0.5906 - accuracy: 0.8281 - val_loss: 0.7907 - val_accuracy: 0.7969\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 0.8121 - accuracy: 0.7656 - val_loss: 0.8230 - val_accuracy: 0.8672\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 0.7997 - accuracy: 0.7656 - val_loss: 0.8450 - val_accuracy: 0.8281\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 1s 392ms/step - loss: 0.7475 - accuracy: 0.7969 - val_loss: 0.6257 - val_accuracy: 0.8828\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.7406 - accuracy: 0.7969 - val_loss: 0.7043 - val_accuracy: 0.7812\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.7353 - accuracy: 0.7891 - val_loss: 0.7355 - val_accuracy: 0.8203\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 1s 277ms/step - loss: 0.6220 - accuracy: 0.7891 - val_loss: 0.6508 - val_accuracy: 0.8203\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.8974 - accuracy: 0.7344 - val_loss: 0.6294 - val_accuracy: 0.8125\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.7297 - accuracy: 0.7188 - val_loss: 0.6103 - val_accuracy: 0.7969\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.6487 - accuracy: 0.8203 - val_loss: 0.7070 - val_accuracy: 0.7422\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6027 - accuracy: 0.8594 - val_loss: 0.5428 - val_accuracy: 0.8672\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.7531 - accuracy: 0.7500 - val_loss: 0.6851 - val_accuracy: 0.8359\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.8914 - accuracy: 0.7578 - val_loss: 0.5371 - val_accuracy: 0.8828\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.6090 - accuracy: 0.7891 - val_loss: 0.5371 - val_accuracy: 0.8516\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.7560 - accuracy: 0.7109 - val_loss: 0.4914 - val_accuracy: 0.8750\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.7607 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.8516\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.6120 - accuracy: 0.8281 - val_loss: 0.4829 - val_accuracy: 0.8516\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.7243 - accuracy: 0.7969 - val_loss: 0.5715 - val_accuracy: 0.8438\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.9699 - accuracy: 0.7578 - val_loss: 0.4773 - val_accuracy: 0.8906\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.5324 - accuracy: 0.8047 - val_loss: 0.6281 - val_accuracy: 0.8125\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.7950 - accuracy: 0.7422 - val_loss: 0.6260 - val_accuracy: 0.8281\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.7079 - accuracy: 0.8281 - val_loss: 0.6378 - val_accuracy: 0.7969\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 1s 285ms/step - loss: 0.6877 - accuracy: 0.7969 - val_loss: 0.7346 - val_accuracy: 0.7734\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.7931 - accuracy: 0.7656 - val_loss: 0.6163 - val_accuracy: 0.8125\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.7044 - accuracy: 0.8281 - val_loss: 0.6693 - val_accuracy: 0.8125\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.6830 - accuracy: 0.8281 - val_loss: 0.5780 - val_accuracy: 0.8047\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 0.5742 - accuracy: 0.8516 - val_loss: 0.5337 - val_accuracy: 0.7969\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.4782 - accuracy: 0.8828 - val_loss: 0.6502 - val_accuracy: 0.7812\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 1s 280ms/step - loss: 0.7602 - accuracy: 0.7344 - val_loss: 0.4803 - val_accuracy: 0.8203\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.5890 - accuracy: 0.8203 - val_loss: 0.5970 - val_accuracy: 0.7734\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.6758 - accuracy: 0.8281 - val_loss: 0.5355 - val_accuracy: 0.8047\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 1s 260ms/step - loss: 0.6337 - accuracy: 0.8359 - val_loss: 0.4811 - val_accuracy: 0.8516\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.4762 - accuracy: 0.8750 - val_loss: 0.4575 - val_accuracy: 0.8828\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 1s 372ms/step - loss: 0.4842 - accuracy: 0.8672 - val_loss: 0.3914 - val_accuracy: 0.8984\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.8132 - accuracy: 0.7578 - val_loss: 0.5302 - val_accuracy: 0.8281\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 1s 303ms/step - loss: 0.6626 - accuracy: 0.7812 - val_loss: 0.4425 - val_accuracy: 0.8516\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5164 - accuracy: 0.8203 - val_loss: 0.5186 - val_accuracy: 0.8203\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.6192 - accuracy: 0.7656 - val_loss: 0.4775 - val_accuracy: 0.8359\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 1s 358ms/step - loss: 0.7577 - accuracy: 0.7500 - val_loss: 0.5955 - val_accuracy: 0.7891\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.7163 - accuracy: 0.7734 - val_loss: 0.4461 - val_accuracy: 0.8125\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.5231 - accuracy: 0.8359 - val_loss: 0.3861 - val_accuracy: 0.8828\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.5993 - accuracy: 0.8125 - val_loss: 0.6083 - val_accuracy: 0.7891\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 0.8558 - accuracy: 0.7812 - val_loss: 0.4250 - val_accuracy: 0.8516\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.7424 - accuracy: 0.7969 - val_loss: 0.4725 - val_accuracy: 0.8047\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.5486 - accuracy: 0.8281 - val_loss: 0.4130 - val_accuracy: 0.8359\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.6853 - accuracy: 0.7969 - val_loss: 0.4012 - val_accuracy: 0.8906\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.7388 - accuracy: 0.7891 - val_loss: 0.5001 - val_accuracy: 0.8438\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 1s 272ms/step - loss: 0.3816 - accuracy: 0.8828 - val_loss: 0.6958 - val_accuracy: 0.7812\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.6725 - accuracy: 0.7969 - val_loss: 0.4872 - val_accuracy: 0.8203\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 1s 278ms/step - loss: 0.6211 - accuracy: 0.8594 - val_loss: 0.3714 - val_accuracy: 0.8672\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 1s 353ms/step - loss: 0.6783 - accuracy: 0.7969 - val_loss: 0.3912 - val_accuracy: 0.8516\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 0.4251 - accuracy: 0.8281 - val_loss: 0.3396 - val_accuracy: 0.9141\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.6294 - accuracy: 0.8125 - val_loss: 0.3479 - val_accuracy: 0.8672\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 1s 269ms/step - loss: 0.8175 - accuracy: 0.7969 - val_loss: 0.4011 - val_accuracy: 0.8750\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.6478 - accuracy: 0.8281 - val_loss: 0.5182 - val_accuracy: 0.8281\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.6670 - accuracy: 0.7891 - val_loss: 0.3334 - val_accuracy: 0.8906\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.5215 - accuracy: 0.8672 - val_loss: 0.5938 - val_accuracy: 0.7891\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.5764 - accuracy: 0.8203 - val_loss: 0.5185 - val_accuracy: 0.8203\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.5933 - accuracy: 0.8281 - val_loss: 0.4038 - val_accuracy: 0.8906\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.6053 - accuracy: 0.8438 - val_loss: 0.3842 - val_accuracy: 0.9062\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4148 - accuracy: 0.8438 - val_loss: 0.3737 - val_accuracy: 0.8828\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.5056 - accuracy: 0.8438 - val_loss: 0.3763 - val_accuracy: 0.8828\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.4913 - accuracy: 0.8203 - val_loss: 0.3577 - val_accuracy: 0.8828\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4887 - accuracy: 0.8828 - val_loss: 0.6162 - val_accuracy: 0.8281\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4944 - accuracy: 0.8281 - val_loss: 0.3744 - val_accuracy: 0.8906\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.5861 - accuracy: 0.8125 - val_loss: 0.4896 - val_accuracy: 0.8828\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.4012 - accuracy: 0.8828 - val_loss: 0.6539 - val_accuracy: 0.7812\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.3811 - accuracy: 0.8828 - val_loss: 0.4830 - val_accuracy: 0.8516\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.4818 - accuracy: 0.8203 - val_loss: 0.5020 - val_accuracy: 0.8594\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4184 - accuracy: 0.8906 - val_loss: 0.3994 - val_accuracy: 0.8906\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.4521 - accuracy: 0.8516 - val_loss: 0.4294 - val_accuracy: 0.8750\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.4766 - accuracy: 0.8438 - val_loss: 0.4305 - val_accuracy: 0.8828\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.4002 - accuracy: 0.8984 - val_loss: 0.7431 - val_accuracy: 0.8125\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5340 - accuracy: 0.8828 - val_loss: 0.5492 - val_accuracy: 0.8516\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.5400 - accuracy: 0.8438 - val_loss: 0.5306 - val_accuracy: 0.8516\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.5301 - accuracy: 0.8125 - val_loss: 0.4547 - val_accuracy: 0.8594\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.4456 - accuracy: 0.8594 - val_loss: 0.5002 - val_accuracy: 0.8672\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.6081 - accuracy: 0.7969 - val_loss: 0.4517 - val_accuracy: 0.8828\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.5422 - accuracy: 0.8516 - val_loss: 0.3853 - val_accuracy: 0.9062\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.3298 - accuracy: 0.9062 - val_loss: 0.4238 - val_accuracy: 0.8750\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.4903 - accuracy: 0.8594 - val_loss: 0.3044 - val_accuracy: 0.9062\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.4712 - accuracy: 0.8594 - val_loss: 0.5013 - val_accuracy: 0.8750\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 1s 248ms/step - loss: 0.6611 - accuracy: 0.8047 - val_loss: 0.4858 - val_accuracy: 0.8594\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.7228 - accuracy: 0.8047 - val_loss: 0.4573 - val_accuracy: 0.8516\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5417 - accuracy: 0.8750 - val_loss: 0.4650 - val_accuracy: 0.8438\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 1s 294ms/step - loss: 0.3208 - accuracy: 0.8828 - val_loss: 0.2787 - val_accuracy: 0.9297\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.4313 - accuracy: 0.8828 - val_loss: 0.4098 - val_accuracy: 0.8984\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.3839 - accuracy: 0.9141 - val_loss: 0.3089 - val_accuracy: 0.8906\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 0.4204 - accuracy: 0.8672 - val_loss: 0.3755 - val_accuracy: 0.8750\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 0.5254 - accuracy: 0.8359 - val_loss: 0.3422 - val_accuracy: 0.8672\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 0.4063 - accuracy: 0.8984 - val_loss: 0.2802 - val_accuracy: 0.8906\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.4797 - accuracy: 0.8906 - val_loss: 0.3615 - val_accuracy: 0.8828\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 0.3603 - accuracy: 0.8672 - val_loss: 0.2956 - val_accuracy: 0.9141\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 1s 298ms/step - loss: 0.4303 - accuracy: 0.8984 - val_loss: 0.2953 - val_accuracy: 0.9219\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 1s 271ms/step - loss: 0.3825 - accuracy: 0.8750 - val_loss: 0.3504 - val_accuracy: 0.9141\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.2703 - accuracy: 0.8984 - val_loss: 0.2458 - val_accuracy: 0.9219\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.3261 - accuracy: 0.9062 - val_loss: 0.2789 - val_accuracy: 0.9141\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.3336 - accuracy: 0.9219 - val_loss: 0.3463 - val_accuracy: 0.8984\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.4266 - accuracy: 0.8672 - val_loss: 0.3427 - val_accuracy: 0.8828\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.4696 - accuracy: 0.8672 - val_loss: 0.3177 - val_accuracy: 0.9141\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.4586 - accuracy: 0.8544 - val_loss: 0.3172 - val_accuracy: 0.8906\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.4063 - accuracy: 0.9062 - val_loss: 0.4113 - val_accuracy: 0.8672\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.4612 - accuracy: 0.8516 - val_loss: 0.3503 - val_accuracy: 0.8828\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.3314 - accuracy: 0.8750 - val_loss: 0.3762 - val_accuracy: 0.8594\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.3537 - accuracy: 0.8906 - val_loss: 0.4075 - val_accuracy: 0.8750\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.3756 - accuracy: 0.8828 - val_loss: 0.4006 - val_accuracy: 0.8672\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5371 - accuracy: 0.8438 - val_loss: 0.2950 - val_accuracy: 0.8984\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.4040 - accuracy: 0.8516 - val_loss: 0.3088 - val_accuracy: 0.8750\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 0.3567 - accuracy: 0.8984 - val_loss: 0.3529 - val_accuracy: 0.9062\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.4148 - accuracy: 0.8672 - val_loss: 0.2702 - val_accuracy: 0.8984\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.5865 - accuracy: 0.8750 - val_loss: 0.5807 - val_accuracy: 0.8203\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.3833 - accuracy: 0.8750 - val_loss: 0.4267 - val_accuracy: 0.8750\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.4927 - accuracy: 0.8750 - val_loss: 0.4112 - val_accuracy: 0.8828\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.4337 - accuracy: 0.8906 - val_loss: 0.4315 - val_accuracy: 0.8750\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.4236 - accuracy: 0.8672 - val_loss: 0.3550 - val_accuracy: 0.8906\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.4561 - accuracy: 0.8750 - val_loss: 0.4010 - val_accuracy: 0.8828\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 1s 201ms/step - loss: 0.3723 - accuracy: 0.8828 - val_loss: 0.2623 - val_accuracy: 0.9141\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.3876 - accuracy: 0.8984 - val_loss: 0.2606 - val_accuracy: 0.9297\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.5910 - accuracy: 0.8359 - val_loss: 0.2613 - val_accuracy: 0.9219\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.4293 - accuracy: 0.8750 - val_loss: 0.4063 - val_accuracy: 0.8750\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 1s 281ms/step - loss: 0.3324 - accuracy: 0.9141 - val_loss: 0.3891 - val_accuracy: 0.8828\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 0.3945 - accuracy: 0.8984 - val_loss: 0.2975 - val_accuracy: 0.9141\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.2809 - accuracy: 0.9062 - val_loss: 0.4771 - val_accuracy: 0.8672\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.3358 - accuracy: 0.8672 - val_loss: 0.4372 - val_accuracy: 0.8750\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 0.4246 - accuracy: 0.8906 - val_loss: 0.2706 - val_accuracy: 0.9141\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 0.4486 - accuracy: 0.8594 - val_loss: 0.3451 - val_accuracy: 0.9219\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.2813 - accuracy: 0.9062 - val_loss: 0.4425 - val_accuracy: 0.8828\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.4660 - accuracy: 0.8672 - val_loss: 0.3243 - val_accuracy: 0.9062\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 0.5271 - accuracy: 0.8516 - val_loss: 0.6398 - val_accuracy: 0.8438\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 1s 234ms/step - loss: 0.5170 - accuracy: 0.8672 - val_loss: 1.0303 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 0.4989 - accuracy: 0.8828 - val_loss: 0.8805 - val_accuracy: 0.8125\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 0.4164 - accuracy: 0.8828 - val_loss: 0.5500 - val_accuracy: 0.8438\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6314 - accuracy: 0.8359 - val_loss: 0.6735 - val_accuracy: 0.7969\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.3555 - accuracy: 0.9062 - val_loss: 0.6392 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.6834 - accuracy: 0.7969 - val_loss: 0.2985 - val_accuracy: 0.9062\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.3248 - accuracy: 0.9297 - val_loss: 0.4422 - val_accuracy: 0.8906\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.5143 - accuracy: 0.8359 - val_loss: 0.5823 - val_accuracy: 0.8359\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.4111 - accuracy: 0.8828 - val_loss: 0.5914 - val_accuracy: 0.8203\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.3182 - accuracy: 0.9219 - val_loss: 0.2837 - val_accuracy: 0.8984\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.5601 - accuracy: 0.8750 - val_loss: 0.5525 - val_accuracy: 0.8359\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.4226 - accuracy: 0.8750 - val_loss: 0.6330 - val_accuracy: 0.8125\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.4385 - accuracy: 0.8516 - val_loss: 0.7108 - val_accuracy: 0.8047\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.6428 - accuracy: 0.8359 - val_loss: 0.4229 - val_accuracy: 0.8672\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 1s 267ms/step - loss: 0.3339 - accuracy: 0.8984 - val_loss: 0.3034 - val_accuracy: 0.9375\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.4267 - accuracy: 0.8594 - val_loss: 0.5399 - val_accuracy: 0.8359\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.2957 - accuracy: 0.9219 - val_loss: 0.5089 - val_accuracy: 0.8438\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.4964 - accuracy: 0.8438 - val_loss: 0.4133 - val_accuracy: 0.8594\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.3083 - accuracy: 0.9141 - val_loss: 0.4447 - val_accuracy: 0.8672\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.3909 - accuracy: 0.8906 - val_loss: 0.4480 - val_accuracy: 0.8047\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.6439 - accuracy: 0.8281 - val_loss: 0.4542 - val_accuracy: 0.8594\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.4445 - accuracy: 0.8672 - val_loss: 0.7281 - val_accuracy: 0.7812\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 0.2348 - accuracy: 0.9453 - val_loss: 0.6531 - val_accuracy: 0.8203\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 1s 227ms/step - loss: 0.3824 - accuracy: 0.8906 - val_loss: 0.7115 - val_accuracy: 0.7891\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.3313 - accuracy: 0.9219 - val_loss: 0.6595 - val_accuracy: 0.8047\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.3885 - accuracy: 0.8750 - val_loss: 0.4944 - val_accuracy: 0.8594\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 1s 335ms/step - loss: 0.3723 - accuracy: 0.8828 - val_loss: 0.6437 - val_accuracy: 0.8281\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.4926 - accuracy: 0.8594 - val_loss: 0.4374 - val_accuracy: 0.8516\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 0.4036 - accuracy: 0.8750 - val_loss: 0.3735 - val_accuracy: 0.8984\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.2648 - accuracy: 0.9297 - val_loss: 0.3660 - val_accuracy: 0.8750\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.4417 - accuracy: 0.8984 - val_loss: 0.4605 - val_accuracy: 0.8594\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.3533 - accuracy: 0.9375 - val_loss: 0.3647 - val_accuracy: 0.8906\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.5107 - accuracy: 0.8984 - val_loss: 0.2577 - val_accuracy: 0.9297\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.3622 - accuracy: 0.8594 - val_loss: 0.4694 - val_accuracy: 0.8906\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.4848 - accuracy: 0.8438 - val_loss: 0.5409 - val_accuracy: 0.8438\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.2849 - accuracy: 0.9141 - val_loss: 0.5544 - val_accuracy: 0.8672\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.4228 - accuracy: 0.8750 - val_loss: 0.5317 - val_accuracy: 0.8438\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.3432 - accuracy: 0.8672 - val_loss: 0.6145 - val_accuracy: 0.8516\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.5951 - accuracy: 0.8125 - val_loss: 0.7230 - val_accuracy: 0.8203\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.2422 - accuracy: 0.9453 - val_loss: 0.6075 - val_accuracy: 0.8203\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.5553 - accuracy: 0.8594 - val_loss: 0.6703 - val_accuracy: 0.8516\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.6085 - accuracy: 0.8438 - val_loss: 0.5809 - val_accuracy: 0.8203\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.3586 - accuracy: 0.8828 - val_loss: 0.7635 - val_accuracy: 0.7578\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.3573 - accuracy: 0.8750 - val_loss: 0.5513 - val_accuracy: 0.8438\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.2594 - accuracy: 0.9375 - val_loss: 0.5388 - val_accuracy: 0.8281\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 1s 214ms/step - loss: 0.2129 - accuracy: 0.9219 - val_loss: 0.4515 - val_accuracy: 0.8516\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 0.2889 - accuracy: 0.8984 - val_loss: 0.5284 - val_accuracy: 0.8594\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.3442 - accuracy: 0.8906 - val_loss: 0.5688 - val_accuracy: 0.8125\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.2476 - accuracy: 0.9375 - val_loss: 0.5320 - val_accuracy: 0.8359\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.5312 - accuracy: 0.8828 - val_loss: 0.4242 - val_accuracy: 0.8906\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.3865 - accuracy: 0.8828 - val_loss: 0.7160 - val_accuracy: 0.7969\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 1s 210ms/step - loss: 0.2961 - accuracy: 0.9219 - val_loss: 0.6296 - val_accuracy: 0.7969\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 1s 229ms/step - loss: 0.5008 - accuracy: 0.8594 - val_loss: 0.6347 - val_accuracy: 0.8281\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 1s 259ms/step - loss: 0.3196 - accuracy: 0.8594 - val_loss: 0.4664 - val_accuracy: 0.8516\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 0.2633 - accuracy: 0.9375 - val_loss: 0.5322 - val_accuracy: 0.8281\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.4115 - accuracy: 0.8984 - val_loss: 0.5414 - val_accuracy: 0.8281\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.3892 - accuracy: 0.9141 - val_loss: 0.4795 - val_accuracy: 0.8594\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 1s 289ms/step - loss: 0.3560 - accuracy: 0.8828 - val_loss: 0.4911 - val_accuracy: 0.8672\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 0.2924 - accuracy: 0.9297 - val_loss: 0.6275 - val_accuracy: 0.8203\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 1s 336ms/step - loss: 0.3076 - accuracy: 0.9141 - val_loss: 0.5081 - val_accuracy: 0.8672\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 0.2907 - accuracy: 0.9297 - val_loss: 0.3867 - val_accuracy: 0.8906\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 1s 275ms/step - loss: 0.2735 - accuracy: 0.9062 - val_loss: 0.3619 - val_accuracy: 0.8984\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9609\n",
      "Reached 95.0% accuracy so cancelling training!\n",
      "4/4 [==============================] - 1s 290ms/step - loss: 0.1367 - accuracy: 0.9609 - val_loss: 0.3828 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samapant\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Note that you'll need to save your model as a .h5 like this.\n",
    "# When you press the Submit and Test button, your saved .h5 model will\n",
    "# be sent to the testing infrastructure for scoring\n",
    "# and the score will be returned to you.\n",
    "if __name__ == '__main__':\n",
    "    model = solution_model()\n",
    "    model.save(\"Question_3.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
